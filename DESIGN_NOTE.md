This setup abstracts real QA automation into a family of directed graphs where nodes are screens and edges are actions (click, type, navigate). Noise and sparsity arise from dead-ends, stochastic pop-ups, and hidden dependencies that emulate real-world latent states (auth, cookies, A/B flags). Observations are intentionally compact (one-hot of the current node), making this a POMDP (partially observable markov decision process) and motivating memory-equipped policies.

We compare value-based (DQN) and policy-gradient (PPO) baselines, then add a recurrent policy (RecurrentPPO) to address partial observability. The graph generator enables training on a distribution of flows and evaluating zero-shot transfer and distribution shifts (deeper graphs, higher popup rates). Metrics include success rate, steps to success, and failure rate. Reproducibility is ensured via fixed seeds, explicit configs, and deterministic plotting.

In production, the same pattern extends by scraping static websites or app navigations into graphs, randomising DOM-specific features for robustness, and optionally warm-starting with offline behaviour cloning from user logs. Memory and exploration remain crucial for reliably reaching rare success paths while handling masking events and latent state.